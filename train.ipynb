{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Linear (nn.Module):\n",
    "    def __init__(self, w, in_w, use_bias=True, activation=None):\n",
    "        super(Linear, self).__init__()\n",
    "        self.W = nn.Parameter(torch.zeros(w, in_w))\n",
    "        self.b = nn.Parameter(torch.zeros(1, w)) if use_bias else None\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            nn.init.zeros_(self.b)\n",
    "\n",
    "        if use_bias:\n",
    "            nn.init.zeros_(self.b)\n",
    "        self.act = activation\n",
    "        if activation == 'relu':\n",
    "            self.act = torch.relu\n",
    "        elif activation == 'sigmoid':\n",
    "            self.act = torch.sigmoid\n",
    "        elif activation == 'tanh':\n",
    "            self.act = torch.tanh\n",
    "        elif activation == 'none':\n",
    "            self.act = torch.nn.Identity()\n",
    "        else:\n",
    "            raise ValueError(f'Activation function {activation} not supported')\n",
    "        \n",
    "        #print(f'Linear layer, W.shape {self.W.shape}. Expected input shape [?, {in_w}], output shape [?, {w}]')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.mm(x, self.W.t())\n",
    "        if self.b is not None:\n",
    "            out += self.b\n",
    "        if self.act:\n",
    "            out = self.act(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, l1:int, l2:int, prob:float, act1:str, act2:str,  in_w:int):\n",
    "        super(FeedForward, self).__init__()\n",
    "        print(f'FeedForward: l1={l1}, l2={l2}, prob={prob}, act1={act1}, act2={act2}, in_w={in_w}')\n",
    "        self.l_in = Linear(l1, in_w, False, act1)\n",
    "        self.dropout = nn.Dropout(prob)\n",
    "        self.l_out = Linear(l2, l1, True, act2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l_out(self.dropout(self.l_in(x)))\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, w, in_w, use_bias=False, activation=None):\n",
    "        super(Attention, self).__init__()\n",
    "        print(f'Attention, w={w}, in_w={in_w}, use_bias={use_bias}, activation={activation}')\n",
    "        self.Q = Linear(w, in_w, use_bias, activation)\n",
    "        self.K = Linear(w, in_w, use_bias, activation)\n",
    "        self.V = Linear(w, in_w, use_bias, activation)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "        qkt = torch.mm(q, k.t())\n",
    "        qkt /= torch.sqrt(torch.tensor(k.size(1), dtype=torch.float32))\n",
    "        qkt = torch.softmax(qkt, dim=1)\n",
    "        return torch.mm(qkt, v)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n, w, in_w, use_bias=True, activation=None):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        print(f'MultiHeadAttention, n={n}, w={w}, in_w={in_w}, use_bias={use_bias}, activation={activation}')\n",
    "        self.heads = [Attention(w,in_w, use_bias, activation) for _ in range(n)]\n",
    "        self.out = Linear(w, w * n, use_bias, activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outs = [head(x) for head in self.heads]\n",
    "        head_out = torch.cat(head_outs, dim=1)\n",
    "        x = self.out(head_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger MHA - MLP model\n",
    "import random\n",
    "\n",
    "torch.manual_seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "class EmoModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.MLP1 = FeedForward(192, 128, 0.5, 'relu', 'tanh', 300)\n",
    "        self.MHA1 = MultiHeadAttention(1, 64, 128, False, 'relu')\n",
    "        self.Lin1 = Linear(6, 64, False, 'sigmoid')\n",
    "        self.Lin2 = Linear(1, 64, False, 'sigmoid')\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.MLP1(x)\n",
    "        x = self.MHA1(x)\n",
    "        x = self.Lin1(x)\n",
    "        x = x.t()\n",
    "        x = self.Lin2(x)\n",
    "        x = self.softmax(x).t()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris data and model\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('static_data/iris_train.csv')\n",
    "# convert last column of df to class\n",
    "df['class'] = df['variety'].map({'Setosa': [0, 0, 1], 'Versicolor': [0, 1, 0], 'Virginica': [1, 0, 0]})\n",
    "del df['variety']\n",
    "iris_data = df.to_numpy()\n",
    "np.random.seed(20)\n",
    "np.random.shuffle(iris_data)\n",
    "\n",
    "import torch.nn as nn\n",
    "class IrisModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.seq = nn.Sequential(\n",
    "        #    nn.Linear(4, 16),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Linear(16, 3),\n",
    "        #)\n",
    "        self.seq = FeedForward(16, 3, .25, 'relu', 'none', 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read emotion dataset.\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def read_vectors(file):\n",
    "    vectors = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                word, *vector = line.split()\n",
    "                vectors[word] = torch.tensor([float(x) for x in vector])\n",
    "            except:\n",
    "                print(\"Failed to read line\", line)\n",
    "                pass\n",
    "    return vectors\n",
    "\n",
    "vec_file = '/home/ishwark/word2vecdata/wiki.multi.en.vec'\n",
    "pickle_file = '/home/ishwark/word2vecdata/word2idx.pkl'\n",
    "\n",
    "if not os.path.exists(pickle_file):\n",
    "    print(\"writing pickles\")\n",
    "    vecs = read_vectors(vec_file)\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(vecs, f)\n",
    "\n",
    "with open('/home/ishwark/word2vecdata/word2idx.pkl', 'rb') as f:\n",
    "    vecs = pickle.load(f)\n",
    "\n",
    "\n",
    "# read a text file with the following format\n",
    "# word1 word2 word3 ... wordn, int\n",
    "\n",
    "def read_sentences(file):\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            try:\n",
    "                words, label = line.split(',')\n",
    "                label = F.one_hot(torch.tensor(int(label)), num_classes=6).float()\n",
    "                data.append((words.split(), label))\n",
    "            except:\n",
    "                print(\"Failed to read line\", line)\n",
    "    return data\n",
    "\n",
    "def sentence_to_tensor(sentence, vectors, max_words=64):\n",
    "    sentence = sentence[:max_words]\n",
    "    vecs = [vectors[word] for word in sentence if word in vectors]\n",
    "    vecs += [torch.zeros_like(vecs[0]) for _ in range(max_words - len(vecs))]\n",
    "    return torch.stack(vecs)\n",
    "\n",
    "sents = read_sentences('/home/ishwark/word2vecdata/emotion/split/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Iris model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(precision=10, sci_mode=False, edgeitems=2000)\n",
    "np.random.seed(20)\n",
    "torch.manual_seed(10)\n",
    "\n",
    "model = IrisModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "batch_losses = [0]\n",
    "err_cts = list([0])\n",
    "weight_norms = []\n",
    "grad_norms = []\n",
    "sample = 0\n",
    "file = open('error.txt', 'w')\n",
    "n, f = [None, None], [None, None]\n",
    "loss2 = torch.nn.MSELoss()\n",
    "optimizer.zero_grad()\n",
    "batch_size = 32\n",
    "\n",
    "while True:\n",
    "    #random.shuffle(sents)\n",
    "    #for sentence, label in sents:\n",
    "    for row in iris_data:\n",
    "        #x = sentence_to_tensor(sentence, vecs)\n",
    "        x1 = torch.from_numpy(np.array(row[:-1], dtype=float))\n",
    "        t = torch.tensor(row[-1])\n",
    "        y = model(x1.view(1, -1).float())\n",
    "        t = t.view(1, -1).float()\n",
    "\n",
    "        l = loss(y, t)\n",
    "        l.backward()\n",
    "\n",
    "        err_cts[-1] += (torch.argmax(t) != torch.argmax(y)).item()\n",
    "        batch_losses[-1] += l.item()\n",
    "        if (sample + 1) % batch_size == 0:\n",
    "            batch = sample // batch_size\n",
    "            \n",
    "            model.eval()\n",
    "            y = model(x1.view(1, -1).float())\n",
    "            t = t.view(1, -1).float()\n",
    "            l = loss2(y, t)\n",
    "\n",
    "            if batch % 100 == 0 and False:\n",
    "                lout_w_norm = model.seq.l_out.W.norm(p=2).item()\n",
    "                lin_w_norm = model.seq.l_in.W.norm(p=2).item()\n",
    "                lout_wg_norm = model.seq.l_out.W.grad.norm(p=2).item()\n",
    "                lin_wg_norm = model.seq.l_in.W.grad.norm(p=2).item()\n",
    "                weight_norms.append((batch, lin_w_norm, lout_w_norm ))\n",
    "                grad_norms.append((batch, lin_wg_norm, lout_wg_norm))\n",
    "                print( batch, f\"\\nl_out W | G norm: {lout_w_norm:2.3f} | {lout_wg_norm:2.3f} \",\n",
    "                              f\"\\nl_out W | G norm: {lin_w_norm:2.3f} | {lin_wg_norm:2.3f} \")\n",
    "\n",
    "            print(sample, err_cts[-1], l.item(), y.tolist(), t.tolist(), file=file)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            batch_losses[-1] /= batch_size\n",
    "            batch_losses.append(0)\n",
    "            err_cts.append(0)\n",
    "        sample += 1 \n",
    "    if sample > batch_size * 2500:\n",
    "        break\n",
    "batch_losses = [(i, l) for i, l in enumerate(batch_losses)]\n",
    "err_cts = [(i, l) for i, l in enumerate(err_cts)]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Iris Python train\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "main_plot = batch_losses[:-1]\n",
    "\n",
    "y1 = np.array([t[0] for t in main_plot])\n",
    "x1 = np.array([t[1] for t in main_plot])\n",
    "\n",
    "y2 = np.array([t[0] for t in weight_norms])\n",
    "x2 = np.array([t[1] for t in weight_norms])\n",
    "\n",
    "y3 = np.array([t[0] for t in grad_norms[1:-1]])\n",
    "x3 = np.array([t[1] for t in grad_norms[1:-1]])\n",
    "\n",
    "smoothed = pd.Series(x1).rolling(window=16).mean().to_numpy()[16:]\n",
    "\n",
    "transparent_red = (1,0,0,.5)\n",
    "plt.plot(y1, x1, label=\"err_ct\", color='orange', alpha=.5)\n",
    "plt.plot(y1[16:], smoothed, label=\"smoothed\", color='orange')\n",
    "#plt.plot(y2, x2, '-x', label=\"w_norm\", color='blue', alpha=.5)\n",
    "#plt.plot(y3, x3, label=\"g_norm\", color='green', alpha=.5)\n",
    "\n",
    "plot_title = \"Train Loss/Validation Loss\"\n",
    "plt.title(plot_title)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data from \"losses.csv\", from C++ training\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_losses.csv\")\n",
    "df = df[:]\n",
    "y = np.array(df[\"batch\"])\n",
    "x1 =  np.array(df[\"loss\"])\n",
    "x2 = np.array(df[\"misses\"])\n",
    "smooth_loss = np.array(df['loss'].rolling(window=16).mean())\n",
    "smooth_err = np.array(df['misses'].rolling(window=16).mean())\n",
    "\n",
    "plot_loss = True\n",
    "transparent_red = (1,0,0,.5)\n",
    "if plot_loss:\n",
    "    plt.plot(y, x1, label=\"train_loss\", color='orange', alpha=.33)\n",
    "    plt.plot(y, smooth_loss, label=\"train_loss_16\", color='orange', alpha=1.)\n",
    "else:\n",
    "    plt.plot(y, x2, label=\"misses\", color='cyan', alpha=0.15)\n",
    "    plt.plot(y, smooth_err, label=\"smooth_misses\", color='cyan', alpha=1.)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"valdn_losses.csv\")\n",
    "    v_batches = np.array(df[\"batch\"])\n",
    "    v_losses =  np.array(df[\"loss\"])\n",
    "    v_misses = np.array(df[\"misses\"])\n",
    "    if plot_loss:\n",
    "        plt.plot(v_batches, v_losses, label=\"valdn_loss\", color='teal')\n",
    "    else:\n",
    "        plt.plot(v_batches, v_misses, label=\"v_misses\", color='teal')\n",
    "except:\n",
    "    ...\n",
    "\n",
    "plot_title = \"Train Loss/Validation Loss\"\n",
    "plt.title(plot_title)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
